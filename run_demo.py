#!/usr/bin/env python3
"""
MedForge Demo Script

Demonstrates the three-pipeline architecture without requiring LLM API keys.
This offline demo shows the output format and processing flow.

For full LLM-powered processing, configure API keys in .env and run:
    python run_all.py

Usage:
    python run_demo.py
"""

import re
from pathlib import Path
from datetime import datetime


ROOT = Path(__file__).parent
INPUT_DIR = ROOT / "demo" / "input"
OUTPUT_DIR = ROOT / "demo" / "output"


def read_file(path: Path) -> str:
    """Read text file with UTF-8 encoding."""
    return path.read_text(encoding="utf-8")


def write_file(path: Path, content: str) -> None:
    """Write text file, creating directories if needed."""
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(content, encoding="utf-8")


def md_header(title: str) -> str:
    """Generate markdown header with timestamp."""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M")
    return f"# {title}\n\n_Generated by MedForge Demo | {timestamp}_\n\n---\n\n"


# =============================================================================
# Pipeline 1: Exercise Processing
# =============================================================================

def parse_exercises(text: str) -> list[dict]:
    """Parse exercise text into structured questions."""
    questions = []

    # Split into blocks by question number
    blocks = re.split(r'\n(?=\d+\.)', text)

    for block in blocks:
        block = block.strip()
        if not block:
            continue

        # Extract question number and stem
        match = re.match(r'(\d+)\.\s*(.+?)(?=\n[A-D]\.|\nAnswer:)', block, re.DOTALL)
        if not match:
            continue

        q_id = match.group(1)
        stem = match.group(2).strip()

        # Extract options
        options = re.findall(r'([A-D])\.\s*(.+?)(?=\n[A-D]\.|\nAnswer:|$)', block, re.DOTALL)
        options = {opt[0]: opt[1].strip() for opt in options}

        # Extract answer
        ans_match = re.search(r'Answer:\s*([A-D])', block)
        answer = ans_match.group(1) if ans_match else None

        if options:  # Only include if has options (MCQ)
            questions.append({
                "id": q_id,
                "stem": stem,
                "options": options,
                "answer": answer
            })

    return questions


def generate_exercise_output(questions: list[dict]) -> str:
    """Generate exercise solutions markdown."""
    lines = [md_header("Biology Exercise Solutions (Demo)")]

    for q in questions:
        lines.append(f"### {q['id']}. {q['stem']}\n")

        for opt_key, opt_text in sorted(q['options'].items()):
            lines.append(f"- **{opt_key}**. {opt_text}")

        lines.append("")

        if q['answer']:
            lines.append(f"> **Answer**: {q['answer']}\n")
            lines.append(f"**Explanation**: This question tests understanding of core biological concepts. ")
            lines.append(f"Option {q['answer']} is correct based on the textbook material.\n")

        lines.append("---\n")

    lines.append("\n_Demo output - Full version includes detailed LLM-generated explanations_")
    return "\n".join(lines)


# =============================================================================
# Pipeline 2: Key Points Extraction
# =============================================================================

def extract_key_concepts(textbook: str) -> list[str]:
    """Extract key concepts from textbook text."""
    concepts = []

    # Extract sentences containing key indicator words
    keywords = [
        "are the", "is the", "responsible for", "include",
        "contains", "produces", "results in", "leads to",
        "important", "essential", "fundamental", "key"
    ]

    sentences = re.split(r'[.!?]+', textbook)

    for sent in sentences:
        sent = sent.strip()
        if len(sent) < 20:
            continue
        if any(kw in sent.lower() for kw in keywords):
            # Clean up the sentence
            sent = re.sub(r'\s+', ' ', sent)
            if sent and not sent.endswith('.'):
                sent += '.'
            concepts.append(sent)

    return concepts[:20]  # Limit to top 20


def generate_keypoints_output(concepts: list[str], questions: list[dict]) -> str:
    """Generate key points summary markdown."""
    lines = [md_header("Biology Key Points Summary (Demo)")]

    # Part 1: Overview
    lines.append("## Part 1: Chapter Overview\n")
    lines.append("This chapter covers fundamental concepts in cell biology, molecular genetics, ")
    lines.append("and cell division. These topics form the foundation of modern biology.\n")

    # Part 2: Key Concepts
    lines.append("## Part 2: Key Concepts\n")
    for i, concept in enumerate(concepts, 1):
        lines.append(f"- {concept}")
    lines.append("")

    # Part 3: Question Mapping
    lines.append("## Part 3: Question Mapping\n")
    lines.append("| Q# | Topic | Notes |")
    lines.append("|:---|:------|:------|")

    for q in questions:
        # Extract topic from stem (first few words)
        topic = ' '.join(q['stem'].split()[:5]) + "..."
        lines.append(f"| Q{q['id']} | {topic} | Core concept |")

    lines.append("\n---\n")
    lines.append("\n_Demo output - Full version includes detailed concept analysis_")
    return "\n".join(lines)


# =============================================================================
# Pipeline 3: PPT Integration
# =============================================================================

def extract_slide_points(slides: str) -> list[dict]:
    """Extract points from slide text."""
    slide_data = []
    current_slide = None

    for line in slides.split('\n'):
        line = line.strip()
        if not line:
            continue

        # Check for slide header
        slide_match = re.match(r'Slide\s+(\d+):\s*(.+)', line)
        if slide_match:
            if current_slide:
                slide_data.append(current_slide)
            current_slide = {
                "number": slide_match.group(1),
                "title": slide_match.group(2),
                "points": []
            }
        elif line.startswith('-') and current_slide:
            point = line.lstrip('- ').strip()
            if point:
                current_slide["points"].append(point)

    if current_slide:
        slide_data.append(current_slide)

    return slide_data


def generate_lecture_output(slides: list[dict], textbook: str) -> str:
    """Generate integrated lecture notes markdown."""
    lines = [md_header("Biology Integrated Lecture Notes (Demo)")]

    lines.append("## Lecture Overview\n")
    lines.append("This document integrates PPT slide content with textbook material ")
    lines.append("to create comprehensive lecture notes.\n")

    current_lecture = None

    for slide in slides:
        # Check if this starts a new lecture
        if slide["title"].startswith("Introduction") or int(slide["number"]) in [1, 5, 9]:
            if current_lecture:
                lines.append("---\n")
            current_lecture = slide["title"]
            lines.append(f"## {slide['title']}\n")
        else:
            lines.append(f"### {slide['title']}\n")

        # Add slide points
        if slide["points"]:
            lines.append("**Key Points from Slides:**\n")
            for point in slide["points"]:
                lines.append(f"- {point}")
            lines.append("")

        # Add textbook context (simulated)
        lines.append("**Textbook Reference:**\n")
        lines.append("> Detailed explanation available in the corresponding textbook section.\n")

    lines.append("---\n")
    lines.append("\n_Demo output - Full version includes deep LLM-powered integration_")
    return "\n".join(lines)


# =============================================================================
# Main Demo Runner
# =============================================================================

def main():
    """Run the demo pipeline."""
    print("=" * 60)
    print("MedForge Demo - Three-Pipeline Architecture")
    print("=" * 60)
    print()

    # Check input files exist
    textbook_path = INPUT_DIR / "biology_textbook.txt"
    exercises_path = INPUT_DIR / "biology_exercises.txt"
    slides_path = INPUT_DIR / "biology_slides.txt"

    if not all(p.exists() for p in [textbook_path, exercises_path, slides_path]):
        print("[ERROR] Demo input files not found in demo/input/")
        print("Please ensure the following files exist:")
        print("  - demo/input/biology_textbook.txt")
        print("  - demo/input/biology_exercises.txt")
        print("  - demo/input/biology_slides.txt")
        return

    # Read input files
    print("[1/4] Reading input files...")
    textbook = read_file(textbook_path)
    exercises = read_file(exercises_path)
    slides = read_file(slides_path)
    print(f"      Textbook: {len(textbook):,} chars")
    print(f"      Exercises: {len(exercises):,} chars")
    print(f"      Slides: {len(slides):,} chars")
    print()

    # Pipeline 1: Exercise Processing
    print("[2/4] Pipeline 1: Processing exercises...")
    questions = parse_exercises(exercises)
    exercise_output = generate_exercise_output(questions)
    write_file(OUTPUT_DIR / "Biology_exercises_demo.md", exercise_output)
    print(f"      Parsed {len(questions)} questions")
    print(f"      Output: demo/output/Biology_exercises_demo.md")
    print()

    # Pipeline 2: Key Points Extraction
    print("[3/4] Pipeline 2: Extracting key points...")
    concepts = extract_key_concepts(textbook)
    keypoints_output = generate_keypoints_output(concepts, questions)
    write_file(OUTPUT_DIR / "Biology_key_points_demo.md", keypoints_output)
    print(f"      Extracted {len(concepts)} key concepts")
    print(f"      Output: demo/output/Biology_key_points_demo.md")
    print()

    # Pipeline 3: PPT Integration
    print("[4/4] Pipeline 3: Integrating lecture notes...")
    slide_data = extract_slide_points(slides)
    lecture_output = generate_lecture_output(slide_data, textbook)
    write_file(OUTPUT_DIR / "Biology_lecture_demo.md", lecture_output)
    print(f"      Processed {len(slide_data)} slides")
    print(f"      Output: demo/output/Biology_lecture_demo.md")
    print()

    # Summary
    print("=" * 60)
    print("Demo Complete!")
    print("=" * 60)
    print()
    print("Output files generated in: demo/output/")
    print()
    print("This demo shows the output FORMAT without LLM processing.")
    print("For full LLM-powered output, see: demo/output_example/")
    print()
    print("To run with real LLM processing:")
    print("  1. Copy .env.example to .env")
    print("  2. Add your API key(s)")
    print("  3. Run: python run_all.py")
    print()


if __name__ == "__main__":
    main()
